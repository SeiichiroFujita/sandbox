import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM

#関数get_standardized_tの定義
def get_standardized_t(X, num_date):
    X = np.array(X)
    X_t_list = []
    for i in range(len(X) - num_date + 1):
        X_t = X[i:i+num_date]
        scaler = StandardScaler()
        X_standardized = scaler.fit_transform(X_t)
        X_t_list.append(X_standardized)
    return np.array(X_t_list)

#学習データの読み込み
train = pd.read_csv("../input/train.csv")
#評価データの読み込み
test = pd.read_csv("../input/test.csv")

#trainデータの前処理
# trainのデータ型の変更
train["Date"] = pd.to_datetime(train["Date"], format='%Y-%m-%d')
# データの並び替え
train.sort_values(by="Date", ascending=True, inplace=True)
# インデックスの更新
train.set_index(keys="Date", inplace=True)
# OpenとCloseの差額を計算
train['Body'] = train["Open"] - train["Close"]
# 新たな説明変数Rateを作成
train_rate = (train["Close"]-train["Close"].shift(1))/train["Close"].shift(1)
train_rate = train_rate.fillna(0)
train["Rate"] = train_rate
# 説明変数をX_trainに格納
X_train_tmp = train.drop(columns=["Up"],inplace=False)
# 目的変数をy_trainに格納
y_train_tmp = train["Up"]
# 学習データと検証データに75:25の割合で2分割する
X_train, X_val, y_train, y_val = train_test_split(X_train_tmp, y_train_tmp, test_size=0.25, shuffle=False)
# 期間の設定
num_date = 6
# 関数get_standardizedの呼び出し
X_train_t = get_standardized_t(X=X_train, num_date=num_date)
X_val_t = get_standardized_t(X=X_val, num_date=num_date)
# 目的変数の変形
y_train_t = y_train[num_date-1:]
y_val_t = y_val[num_date-1:]

# ネットワークの各層のサイズの定義
num_l1 = 100
num_l2 = 20
num_output = 1

# 以下、ネットワークを構築
model = Sequential()
# 第1層
model.add(LSTM(units=num_l1,
                activation='tanh',
                batch_input_shape=(None, X_train_t.shape[1], X_train_t.shape[2])))
# 第2層
model.add(Dense(num_l2, activation='relu'))
# 出力層
model.add(Dense(num_output, activation='sigmoid'))
# ネットワークのコンパイル
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# モデルの学習の実行
result = model.fit(x=X_train_t, y=y_train_t, epochs=30, batch_size=24, validation_data=(X_val_t, y_val_t))

#関数get_standardized_testの定義
def get_standardized_test(X, num_date):
    X = np.array(X)
    X_t_list = []
    for i in range(100):
        X_t = X[i*6:i*6+6]
        scaler = StandardScaler()
        X_standardized = scaler.fit_transform(X_t)
        X_t_list.append(X_standardized)
    return np.array(X_t_list)

#testデータの前処理
# testのデータ型の変更
test["Date"] = pd.to_datetime(test["Date"], format='%Y-%m-%d')
# データの並び替え
test.sort_values(by="Date", ascending=True, inplace=True)
# インデックスの更新
test.set_index(keys="Date", inplace=True)
# OpenとCloseの差額を計算
test['Body'] = test["Open"] - test["Close"]
# 新たな説明変数Rateを作成
test_rate = (test["Close"]-test["Close"].shift(1))/test["Close"].shift(1)
test_rate = test_rate.fillna(0)
test["Rate"] = test_rate
# 関数get_standardizedの呼び出し
X_test_t = get_standardized_test(X=test, num_date=num_date)

# 関数get_standardizedの呼び出し
X_test_t = get_standardized_test(X=test, num_date=num_date)

# 評価データの予測結果の算出
pred_prob = model.predict(X_test_t)

# 評価データの予測結果を0もしくは1に丸め込み
pred_tmp = np.round(pred_prob)

pred = pred_tmp.astype(int)

submit = pd.read_csv("../input/sample_submission.csv", header=None)

submit[1] = pred
submit.to_csv("submit.csv", index=False, header=False)




